{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Organization & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Gets necessary imports\n",
    "import numpy as np\n",
    "import heapq\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "boba_data_set = pd.read_csv('bayarea_boba_spots.csv') # Reads the boba data set\n",
    "\n",
    "# Organizes the boba data into their own individual variables\n",
    "shop_names = boba_data_set['name'] # Gets all shop names\n",
    "ratings = boba_data_set['rating'] # Gets all ratings\n",
    "cities = boba_data_set['city'] # Gets all cities\n",
    "latitudes = boba_data_set['lat'] # Gets the latitudes\n",
    "longitudes = boba_data_set['long'] # Gets the Longitudes\n",
    "# Hashamp(or dictionary) is used to pair the names with the scores for easy access, and averages any repeated shop names\n",
    "# In each pair, the key will represent the store name, and the value will be a \n",
    "# numpy array holding two values: First index will be the average ratings,\n",
    "# and the second will be the total quantity of that specific shop\n",
    "hashmap = {}\n",
    "for i in range(len(shop_names)):\n",
    "    # Checks if the current shop already exist inside the hashmap, and add that to our total value.\n",
    "    if shop_names[i] in hashmap:\n",
    "        shop_arr = hashmap[shop_names[i]]\n",
    "        shop_arr[1] += 1\n",
    "        shop_arr[0] += float(ratings[i])\n",
    "    # Initializes a new shop if it is not already present inside the hashmap\n",
    "    else:\n",
    "        new_arr = [0,0]\n",
    "        new_arr[0] = float(ratings[i])\n",
    "        new_arr[1] = 1\n",
    "        hashmap[shop_names[i]] = new_arr\n",
    "\n",
    "# We now average all the ratings if they have more than one shop \n",
    "for current in hashmap.keys():\n",
    "    pair = hashmap[current]\n",
    "    avg = pair[0] / pair[1]\n",
    "    hashmap[current][0] = avg\n",
    "\n",
    "\n",
    "housing_data_set = pd.read_csv('housing.csv') # Reads the housing data set\n",
    "\n",
    "# Organizes the housing data into their own individual variables\n",
    "longitudes_house = housing_data_set['longitude'] # Gets the longitudes of the houses\n",
    "latitudes_house = housing_data_set['latitude'] # Gets the latitidues of the houses\n",
    "house_values = housing_data_set['median_house_value'] # Gets the median house values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bobateani', 'Golden Bakery', 'Honey Bear Smoothie Tea & Dessert', 'Puppy Bobar', 'QTeaBar', 'Taza Deli & Cafe', 'Waterfront Cafe', '5 Sweets', '99% Tea House', 'Alice Street Bakery Caf√©', 'Aloha Pure Water Shaved Ice', \"Antoine's Cookie Shop\", 'Aqua Club Dessert & Beverage', 'Aung Maylika', 'Banh Mi Ba Le', 'BaoTea Cafe', 'Blue Saigon', 'Calibear Cyber Cafe', 'Chantal Guillon Macarons & Teas', 'Che-Lo', 'Chilly & Munch', 'Cornology', 'DAVIDsTEA', 'Easel', 'Eat On Monday']\n",
      "[5.  5.  5.  5.  5.  5.  5.  4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5\n",
      " 4.5 4.5 4.5 4.5 4.5 4.5 4.5]\n"
     ]
    }
   ],
   "source": [
    "# First we will do an amounts bar graph visualization where the x axis will represent boba shops,\n",
    "#  and the y axis will represent the rating\n",
    "\n",
    "# We will graph the top 25 and the lowest 25 rating stores since there are so many.\n",
    "\n",
    "\n",
    "# Top 25 Scores:\n",
    "\n",
    "# We will use a priority queue for this portion since its easier to get the top 25 values\n",
    "prio_queue = []\n",
    "top_25_stores_ratings = np.zeros(25)\n",
    "top_25_stores_names = []\n",
    "checker = set()\n",
    "for i in range(len(shop_names)):\n",
    "    if shop_names[i] in checker:\n",
    "        continue\n",
    "    new_list = [0,0,0]\n",
    "    pair = hashmap[shop_names[i]]\n",
    "    new_list[0] = pair[0] * -1\n",
    "    new_list[1] = pair[1] * - 1\n",
    "    new_list[2] = str(shop_names[i])\n",
    "    heapq.heappush(prio_queue, new_list)\n",
    "    checker.add(shop_names[i])\n",
    "    \n",
    "for i in range(25):\n",
    "    current = heapq.heappop(prio_queue)\n",
    "    top_25_stores_ratings[i] = current[0] * -1\n",
    "    top_25_stores_names.append(current[2])\n",
    "print(top_25_stores_names)\n",
    "print(top_25_stores_ratings)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
